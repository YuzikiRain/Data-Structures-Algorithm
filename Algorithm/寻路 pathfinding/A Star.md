F = G + H
- G：起点到当前节点的已花费代价
- H：当前节点到终点的预估代价
- F：总代价

如果G过大，H相对较小，则退化为Dijkstra
如果距离终点太远导致H过大，G相对较小，则退化为最佳优先搜索
相比于最佳优先搜索增加了起点到当前节点的已花费代价，不会盲目地朝着终点前进（如果遇到障碍物，会重新选择总代价较小的节点继续搜索）

### 启发函数（H值预估）

- 曼哈顿（Manhattan）距离：$|x1−x2|+|y1−y2|$ ，即两点横纵坐标差之和
- 欧几里得（Euclidean）距离：$\sqrt{(|x1−x2|^2,|y1−y2|^2)}$，即两点之间的距离
- 切比雪夫（chebyshev）距离：$max(|x1−x2|,|y1−y2|)$，即两点横纵坐标差的最大值
- （Octile）距离：$a+b$

### 关键

- 访问节点，并将后继节点加入优先队列（根据F值大小排序的最小堆）
- 如果F值相同，使用最近加入到OpenList中的节点（否则会变成BFS）



- （如果没有任何障碍，即全是可通行的节点）不断访问那些未访问过的节点，会使得G递增（离起点越来越远），H递减（离终点越来越近），而（相对其他节点）F保持不变。如果有障碍，则遇到障碍时H也会递增（绕行），此时就有可能以其他较小的F值的节点继续迭代。



- 递增性：H值的预估常用的如曼哈顿距离、欧几里得距离等，**H值和当前节点到终点的距离成正比**。最短路径必然经过F值最小的节点（以及其parent祖先）
- 剪枝：一般来说不存在某个节点能传送，再结合递增性，如果只需要一条最短路径的话，当访问到终点时，说明找到了一条从起点到终点的路径，这条路径必然是最短路径（或其中之一），此时可以立即结束迭代并返回路径了。